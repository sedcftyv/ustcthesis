% !TeX root = ../main.tex

\chapter{可微块压缩模型}

\section{引言}

在神经压缩技术中，为了进一步节省显存，在神经纹理与解码网络训练结束后，可以对占用显存较大的神经纹理使用块压缩技术进行压缩。
但由于现有纹理块压缩工具不支持自动微分，无法结合到神经纹理的训练过程中，
因此训练过程无法感知到块压缩带来的影响，对神经纹理进行块压缩会导致模型的重建误差显著增加。
其中一个解决办法是根据块压缩格式定义，实现可微的编解码器，并将其与神经压缩模型
结合，进行端到端联合优化，从而降低神经纹理的块压缩对神经压缩模型造成的重建损失。
目前已有基于可微BC6解码器的应用研究，但由于仅解码器框架的局限性，
只能进行固定编码配置优化。本章提出了一种新颖的DXT格式可微块压缩模型，包括可微编码器、可微解码器与配置选择器，
可以根据编码误差动态选择编码配置。

\section{问题描述与分析}
\label{问题描述}

设计可微块压缩模型前需要分析DXT格式的主要特征，并根据其特征研究编解码过程的本质问题。
DXT格式是BC1至BC7这7种格式的统称，这些格式都将纹理划分为4\times4的纹理块进行压缩存储，
其中BC6格式用于压缩HDR纹理，其余6种格式都用于压缩LDR纹理。
DXT格式压缩纹理时会将纹理块中的像素（纹素）压缩为颜色端点与权重，解压时根据权重对颜色端点进行线性插值。
DXT格式编码过程需要解决的本质问题是对于一组纹素，找到两个颜色端点，并为组内的每个纹素分配一个权重，
使得根据颜色端点与权重解码后的纹素与原始纹素的误差尽可能小。

具体来讲，给定一组纹素 $\mathbf{C}\in\mathbb{R}^{m\times n}$，
需要将其编码为两个颜色端点$\mathbf{e}_0\in\mathbb{R}^n$ 和 $\mathbf{e}_1\in\mathbb{R}^n$，
以及用于插值的权重 $\mathbf{t}\in\mathbb{R}^m$。其中 $m$ 表示该纹素组中的纹素个数，$n$ 表示每个纹素的通道数。
该编码问题可以表示为$P_{m,n}$。

BC1将4\times4纹理块中所有纹素的3通道颜色压缩为2个颜色端点与16个权重。
BC2支持4通道纹理，并将前3个通道使用BC1压缩，第4个通道直接将颜色进行量化
作为权重，相当于为第4个通道使用了0和1两个颜色端点。
BC3同样支持4通道纹理，并将前3个通道使用BC1压缩，第4个通道单独存储两个颜色端点与16个权重。
BC4支持单通道纹理，存储两个颜色端点与16个权重。
BC5支持双通道纹理，每个通道分别存储两个颜色端点与16个权重。

BC6支持3通道的HDR纹理，同时具有14种不同模式，前10种模式为双分区模式，
会将4\times4的纹理块分为两个区域压缩，每个区域分别存储各自的颜色端点与权重。
最后4种模式为单分区模式。

BC7同时支持3通道与4通道纹理，共具有8种不同模式，前4种模式用于压缩3通道纹理，
后4种模式用于压缩4通道纹理。其中模式1、3、7为双分区模式，
模式0和2为三分区模式，模式4、5、6为单分区模式。
模式4和5会将前3个通道与第4个通道分开压缩，并支持前3个通道中的某一个与第4个通道交换，
这种处理方式被称为旋转。

因此DXT格式的编码问题如表\ref{tab:DXTEncodeproblem}所示，其中其中$m_i$表示第$i$个分区中的纹素个数，
对于双分区模式$m_1+m_2=16$，对于三分区模式$m_1+m_2+m_3=16$。
只需要解决$P_{m,n}$就可以解决DXT格式的主要编码问题。
\begin{table}[htbp]
    \centering
    \caption{DXT格式的编码问题}
    \label{tab:DXTEncodeproblem}        
    % \resizebox{6cm}{!}{
    \begin{tabular}{ccccc}
    \toprule
    格式    & 模式 & 编码问题 \\
    \midrule
    BC1   & -  & $P_{16,3}$               \\
    BC2   & - & $P_{16,3}$, $P_{16,1}$    \\
    BC3   & - & $P_{16,3}$, $P_{16,1}$    \\
    BC4   & - & $P_{16,1}$                  \\
    BC5   & - & $P_{16,1}$     \\
    \midrule
    \multirow{2}{*}{BC6}   & 1-10&   $P_{m_1,3}$, $P_{m_2,3}$     \\
       &11-14&  $P_{16,3}$     \\
    \midrule
    \multirow{5}{*}{BC7}   & 1, 3&   $P_{m_1,3}$, $P_{m_2,3}$     \\
        &0, 2&  $P_{m_1,3}$, $P_{m_2,3}$, $P_{m_3,3}$     \\  
        &4, 5&  $P_{16,3}$, $P_{16,1}$     \\    
        &6&  $P_{16,4}$     \\  
        &7&  $P_{m_1,4}$, $P_{m_2,4}$     \\
    \bottomrule
    \end{tabular}
    % }   
\end{table}

除此之外，还需要解决编码过程的量化问题以及优化过程的范围约束问题，本章分别在
\ref{模拟量化}与\ref{范围约束}中讨论了这两个问题。


\section{模型框架}

\subsection{整体框架}

将压缩前的原始纹理定义为$\mathbf{T}\in \mathbb{R}^{w\times h\times c}$，
压缩后的纹理定义为$\mathbf{T}'\in \mathbb{R}^{w\times h\times c}$，
其中$w$、$h$、$c$分别表示纹理的宽度、高度、通道数。
DXT格式编解码器的框架可以使用如下形式表示：
\begin{equation}
    \mathbf{T}'=\text{ConfigSelector}(\text{Decoder}(\text{Encoder}(\mathbf{T})))
\end{equation}
其中Encoder表示编码器，Decoder表示解码器，ConfigSelector表示编码配置选择器。编码器首先将纹理分为4\times4大小的纹理块，
然后对于每个纹理块，使用不同的编码配置进行编码，每个编码配置经过解码器解码得到对应的纹理，
最后编码配置选择器选择编码误差最小的结果作为输出。因此可微块压缩模型也需要包括可微编码器、可微解码器与
配置选择器三个部分。对于BC1至BC5这5种单模式格式，由于仅有一种编码配置，
因此不需要配置选择器。

基于上述DXT格式编解码器的基本框架，本章提出了一种基于DXT格式的可微块压缩模型(Differentiable Block Compression, DBC)， 
基于DBC模型实现的DXT格式可微编码器、可微解码器以及配置选择器
可以作为标准DXT格式编解码器的可微近似加入神经纹理的优化过程，实现端到端优化。
% 从而降低神经纹理的块压缩使神经压缩模型增加的重建误差。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{figures/DBC_22.pdf}
    \caption{可微块压缩模型的整体框架}
    \label{fig:DBC_overview}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{figures/DBC_21.pdf}
    \caption{上游模型为神经压缩时的整体框架}
    \label{fig:DBC_nm}
\end{figure}

DBC模型的整体框架如图\ref{fig:DBC_overview}所示，
其中最左边的输入纹理为神经纹理，
神经纹理经过可微编码器后通过不同编码配置进行了编码，之后每种编码经过
可微解码器进行解码，然后使用配置选择器根据编码误差选择编码配置，
并输出对应的编解码结果，经过可微编解码后的神经纹理
最终作为上游模型的输入。

上游模型为神经压缩时的整体框架如图\ref{fig:DBC_nm}所示，
其中最左边的输入纹理为神经压缩模型中纹理形式的特征网格。
神经网络对可微编解码后的神经特征进行解码，得到最终的重建纹理。

本章提出的DBC模型本身没有需要优化的参数，
因此结合到神经压缩技术并进行联合优化时使用神经压缩模型的损失函数，
除此之外，对于仅支持LDR纹理的BC1至BC5以及BC7格式，
为了使其能存储浮点形式的神经纹理，在神经压缩模型的损失函数中增加了一项
范围损失，从而对神经纹理的值范围进行约束。
对于支持HDR纹理的BC6格式不需要加入范围损失。

DBC模型的伪代码如下：

\begin{algorithm}[H]
    \caption{DBC模型}
    \KwIn{原始纹理$\mathbf{T}\in \mathbb{R}^{w\times h\times c}$，
其中$w$、$h$、$c$分别表示纹理的宽度、高度、通道数。}
    \KwOut{经过可微DXT编解码的纹理$\mathbf{T}'\in \mathbb{R}^{w\times h\times c}$。}
    $\mathbf{T}' \gets \emptyset$ \;
    \For{each 4x4 block $\mathbf{B}$ in $\mathbf{T}$}{
        $//$从编码配置集$\mathcal{I}$中遍历每种编码配置$i$

        $\mathbf{B}' \gets \emptyset$ \;
        \For{each $i$ in $\mathcal{I}$}{
        $\mathbf{B}'_i \gets Decoder(Encoder(\mathbf{B},i))$\;
        $\mathbf{B}' \gets \mathbf{B}'\cup \mathbf{B}'_i$\;
        }
        $\mathbf{B}'_{i^*} \gets ConfigSelector(\mathbf{B}')$\;
        $\mathbf{T}' \gets \mathbf{T}' \cup \mathbf{B}'_{i^*}$
    }
    \Return $\mathbf{T}'$
\end{algorithm}

\subsection{可微编解码器}

编码过程需要解决\ref{问题描述}中的编码问题 $P_{m,n}$ 。即对于给定的4\times4纹理块，
计算这16个纹理像素（纹素）的颜色端点与权重，使其解压缩后的误差尽可能小。
以RGB纹理为例，这个过程的直观理解如下：
将16个纹素的RGB值视为三维空间中的xyz坐标，16个纹素对应了三维空间中的16个点，
找到一条离这16个点距离最近的直线，
这条直线对应的方向向量称为颜色主方向，
然后将16个点投影到直线上，
取距离最远的两个投影点作为颜色端点。
投影点在两个颜色端点构成的线段上的位置即为权重。

DBC模型采用主成分分析法(Principal Component Analysis, PCA)计算
颜色主方向。PCA有两种常见的实现方式，一种方式为根据中心化的数据计算协方差矩阵，
然后对协方差矩阵利用幂迭代等技术进行特征值分解。第二种方式为直接对中心化的数据
矩阵进行奇异值分解(Singular Value Decomposition, SVD)，由于SVD的计算过程梯度
更稳定，因此采用SVD实现PCA。

具体来讲，将编码问题 $P_{m,n}$中的一组纹素的颜色组成的矩阵定义为
$\mathbf{C}\in\mathbb{R}^{m\times n}$，其中 $m$ 表示该纹素组中的纹素个数，$n$ 表示每个纹素的通道数。
中心化的颜色矩阵定义为$\mathbf{C}_{\text{center}}\in\mathbb{R}^{m\times n}$：
\begin{equation}
\mathbf{C}_{\text{center}}=\mathbf{C}-\mathbf{C}_{\text{mean}}
\end{equation}
其中$\mathbf{C}_{\text{mean}}\in\mathbb{R}^{n}$表示这组纹素的颜色均值。
然后对 $\mathbf{C}_{\text{center}}$ 进行奇异值分解(SVD)：
\begin{equation}
\mathbf{C}_{\text{center}}=\mathbf{U}\text{diag}(\mathbf{s})\mathbf{V}^T
\end{equation}
其中$\mathbf{U}\in \mathbb{R}^{m \times m}$，
$\text{diag}(\mathbf{s})\in\mathbb{R}^{m\times n}$，
$\mathbf{V}\in \mathbb{R}^{n\times n}$。
选择 $\mathbf{V}$ 中最大奇异值对应的奇异向量 $\mathbf{v}\in \mathbb{R}^{n}$ 作为颜色主方向。
然后对颜色主方向$\mathbf{v}$进行归一化：
\begin{equation}
    \mathbf{v}'=\frac{\mathbf{v}}{\|\mathbf{v}\|}
\end{equation}
其中$\mathbf{v}'$表示归一化后的颜色主方向，
$\|\mathbf{v}\|$表示向量$\mathbf{v}$的模长。
接着，将中心化的颜色矩阵 $\mathbf{C}_\text{center}$ 投影到归一化的颜色主方向 $\mathbf{v}'$ 上，
得到这组纹素在颜色主方向$\mathbf{v}'$上的投影距离颜色均值$\mathbf{C}_{\text{mean}}$的偏移长度 $\mathbf{l}\in\mathbb{R}^{m}$：
\begin{equation}
\mathbf{l}=\mathbf{C}_{\text{center}}\cdot\mathbf{v}'
\end{equation}
取距离最远的两个投影点作为颜色端点
$\mathbf{e}_0\in\mathbb{R}^n$ 和 $\mathbf{e}_1\in\mathbb{R}^n$：
\begin{align}
\mathbf{e}_0=\mathbf{C}_{\text{mean}}+\mathbf{l}_\text{min}\mathbf{v}\\
\mathbf{e}_1=\mathbf{C}_{\text{mean}}+\mathbf{l}_\text{max}\mathbf{v}
\end{align}
其中$\mathbf{l}_\text{min}$与$\mathbf{l}_\text{max}$分别表示
偏移长度$\mathbf{l}$的最小值与最大值。

最后将纹素组中每个纹素的颜色投影到颜色端点$\mathbf{e}_0$和$\mathbf{e}_1$构成的线段上，
得到每个纹素的权重$\mathbf{t}\in\mathbb{R}^m$：
\begin{align}
    \mathbf{v''}=\frac{\mathbf{e}_1-\mathbf{e}_0}{\|\mathbf{e}_1-\mathbf{e}_0\|}\\
    \mathbf{t}=\frac{(\mathbf{C}-\mathbf{e}_0)\cdot\mathbf{v''}}{\|\mathbf{e}_1-\mathbf{e}_0\|}
\end{align}
其中$\mathbf{v''}$表示颜色端点$\mathbf{e}_0$和$\mathbf{e}_1$构成的向量，
$\mathbf{C}$表示纹素组的颜色矩阵。

编码过程的伪代码如下：

\begin{algorithm}[H]
    \caption{DXT编码}
    \KwIn{编码问题$P_{m,n}$中一组纹素的颜色组成的矩阵$\mathbf{C}\in\mathbb{R}^{m\times n}$，
    其中 $m$ 表示该纹素组中的纹素个数，$n$ 表示每个纹素的通道数。}
    \KwOut{颜色端点$\mathbf{e}_0\in\mathbb{R}^n$和$\mathbf{e}_1\in\mathbb{R}^n$以及插值权重$\mathbf{t}\in\mathbb{R}^m$}
    
    $\mathbf{C}_{\text{mean}} \gets \text{mean}(\mathbf{C})$; \hfill $//$计算颜色均值$\mathbf{C}_{\text{mean}}\in\mathbb{R}^{n}$
    
    % 第二步：中心化颜色矩阵
    $\mathbf{C}_{\text{center}} \gets \mathbf{C} - \mathbf{C}_{\text{mean}}$; \hfill $//$中心化颜色矩阵$\mathbf{C}$
    
    % 第三步：进行奇异值分解 (SVD)
    $ \mathbf{U}, \text{diag}(\mathbf{s}), \mathbf{V}^T \gets \text{SVD}(\mathbf{C}_{\text{center}})$; \hfill $//$对$\mathbf{C}_{\text{center}}$进行奇异值分解
    
    % 第四步：选择主方向
    选择 $\mathbf{V}$ 中最大奇异值对应的奇异向量 $\mathbf{v} \in \mathbb{R}^{n}$作为颜色主方向\;
    
    % 第五步：归一化主方向
    $\mathbf{v}' \gets \frac{\mathbf{v}}{\|\mathbf{v}\|}$; \hfill $//$归一化颜色主方向$\mathbf{v}$
    
    % 第六步：将中心化的颜色矩阵投影到主方向上
    $\mathbf{l} \gets \mathbf{C}_{\text{center}} \cdot \mathbf{v}'$; \hfill $//$将中心化的颜色矩阵投影到主方向上
    
    % 第七步：找到颜色端点
    $\mathbf{e}_0 \gets \mathbf{C}_{\text{mean}} + \mathbf{l}_{\text{min}} \mathbf{v}$; \hfill $//$取距离最远的两个投影点作为颜色端点

    $\mathbf{e}_1 \gets \mathbf{C}_{\text{mean}} + \mathbf{l}_{\text{max}} \mathbf{v}$\;
    
    % 第八步：计算端点之间的方向向量
    $\mathbf{v''} \gets \frac{\mathbf{e}_1 - \mathbf{e}_0}{\|\mathbf{e}_1 - \mathbf{e}_0\|}$; \hfill $//$计算颜色端点构成线段的方向向量
    
    % 第九步：计算每个纹素的权重
    $\mathbf{t} \gets \frac{(\mathbf{C} - \mathbf{e}_0) \cdot \mathbf{v''}}{\|\mathbf{e}_1 - \mathbf{e}_0\|}$; \hfill $//$将颜色投影到线段上得到插值权重
    
    \Return $\mathbf{e}_0,\mathbf{e}_1,\mathbf{t}$\;
\end{algorithm}

解码器进行线性插值得到解压缩的纹素组 $\mathbf{C}'\in\mathbb{R}^{m\times n}$：
\begin{equation}
\mathbf{C}'=\mathbf{e}_0(1-\mathbf{t})+\mathbf{e}_1\mathbf{t}
\end{equation}

解决了编码问题$P_{m,n}$后，DXT格式的编解码过程可以看作一系列
$P_{m,n}$的组合，例如BC7中模式7具有的64种双分区对应64个$P_{m_1,n}$和
$P_{m_2,n}$问题。

\subsection{模拟量化}
\label{模拟量化}

标准DXT格式编码器在编码过程中会对颜色端点与权重进行量化，
除BC6的颜色端点外，BC6的权重和其余6种格式的颜色端点与权重都使用
均匀量化方法进行量化。为了更加接近标准DXT格式编码器，
DBC模型会在编码完成后对颜色端点与权重进行模拟量化：
\begin{equation}\label{eqn-quantize}
    Q(r)=\frac{\left \lfloor r \times (2^{b}-1) \right \rceil}{2^{b}-1}
\end{equation}
其中$r$表示量化前的0-1浮点值，$b$表示量化位数，$Q(r)$表示经过模拟量化的浮点值，$\lfloor \cdot \rceil$表示
用于舍入的Round函数。
由于Round函数的梯度几乎处处为0，
采用神经网络量化领域常用的直通估计器\cite{bengio2013estimating}(Straight-Through Estimator, STE)
使得梯度得以正常传播：
\begin{equation}\label{eqn-7}
    \nabla_{x} \left \lfloor x \right \rceil=1
\end{equation}

DXT格式的均匀量化过程要求量化前的浮点值范围在0-1之间，
而在基于梯度的优化过程中，难以保证颜色端点与权重的数值范围，
因此通过最大最小缩放，在量化前将颜色端点与权重缩放到0-1之间，
模拟量化后再恢复到之前的范围，以权重的缩放为例:
\begin{equation}
    \mathbf{t'}=\frac{\mathbf{t}-\mathbf{t}_\text{min}}{\mathbf{t}_\text{max}-\mathbf{t}_\text{min}}
\end{equation}
\begin{equation}
    \mathbf{t''}=\mathbf{t'}(\mathbf{t}_\text{max}-\mathbf{t}_\text{min})+\mathbf{t}_\text{min}
\end{equation}
其中$\mathbf{t}\in\mathbb{R}^m$表示纹理经过
可微编码后某个编码问题$P_{m,n}$的权重，
$\mathbf{t}_\text{min}$和$\mathbf{t}_\text{max}$表示$\mathbf{t}$中的
最大值与最小值。$\mathbf{t'}$表示$\mathbf{t}$缩放到0-1范围的值。
$\mathbf{t''}$表示$\mathbf{t'}$经过公式\ref{eqn-quantize}的模拟量化后，缩放到原来范围的值。


BC6格式颜色端点的量化过程比较特殊，
会将原始的16位浮点颜色值按照内存中实际存储的二进制值解读为16位整数值，
再进行均匀量化。这个过程属于非均匀量化，较难进行可微模拟，
因此DBC模型对于BC6格式仅对权重进行量化。

\subsection{配置选择器}

对于多模式的BC6与BC7，标准DXT格式编解码器编码每个纹理块的过程中
会尝试搜索多种编码配置，例如使用不同的量化位数、分区以及旋转，
最终选择一种使得编码误差较小的编码配置进行编码。基于梯度的优化过程中神经纹理会不断发生变化，因此具有配置选择器
的DBC模型可以更好地编码神经纹理。

设输入纹理块 $\mathbf{B}\in\mathbb{R}^{b\times n}$，其中 $b$ 是一个纹理块中的纹素个数。
所有配置的集合为 $\mathcal{I}$，针对配置 $i\in\mathcal{I}$ 经过可微编解码后得到的
纹理块为 $\mathbf{B}'_i\in\mathbb{R}^{b\times n}$。
定义编码配置$i$对应的编码误差 $L_i$ 为
\begin{equation}
L_i=\|\mathbf{B}-\mathbf{B}'_i\|_F^2
\end{equation}

配置选择器的功能是对每4\times4纹理块$\mathbf{B}$，在不同编码配置中选择最佳配置，
即选择使得编码误差$L_i$最小的编码配置$i^*$：
\begin{equation}
    i^*=\mathop{\arg\min}\limits_{i} L_i
\end{equation}

为了确定每个编码配置$i$对应的编码误差$L_i$，
本章使用了穷举的方法，对每4\times4纹理块都会使用所有编码配置进行编码，
从而计算每4\times4纹理块所有编码配置对应的编码误差。
由于优化过程需要进行大量迭代，
这会产生显著的计算开销，下一章将针对这一问题进行改进。

由于在计算编码误差之前，已经对每种编码配置都进行了可微编解码，配置选择器可以
直接将使用了$i^*$进行编解码得到的$\mathbf{B}'_{i^*}$作为输出。
\begin{equation}
    \mathbf{B}'_{i^*}=\mathop{\arg\min}\limits_{\mathbf{B}'_i} L_i
\end{equation}
由于$\mathop{\arg\min}$是不可微的，因此使用one-hot加权混合代替$\mathop{\arg\min}$：
\begin{equation}
\mathbf{B}'_{i^*}=\sum_{i\in\mathcal{I}} w_i\mathbf{B}'_i
\end{equation}
其中 $w_i$ 是配置 $i$ 的组合系数。由于
对于每个4\times4纹理块$\mathbf{B}$最终只能选择一种配置进行编码，
因此 $w_i$ 必须是 one-hot 的：
\begin{equation}
    w_i =\left\{\begin{matrix}
        1,& i=\mathop{\arg\min}\limits_{i} L_i
        \\0,& i\ne\mathop{\arg\min}\limits_{i} L_i
        \end{matrix}\right.
\end{equation}

\subsection{范围约束}
\label{范围约束}

浮点形式的神经纹理一般只能使用支持HDR纹理的BC6格式压缩。
而BC7格式的RGBA模式在相同存储空间下相比仅支持RGB通道的BC6格式可以额外存储一个通道数据。
为了使用BC7格式存储神经纹理，需要对神经纹理的范围进行限制。
为了更好的数值对称性，向神经压缩模型的损失函数中加入范围约束损失：
\begin{equation}
L_{clamp}(\mathbf{T})=\|\mathbf{T}-\text{clamp}(\mathbf{T},-1,1)\|_F^2
\end{equation}
其中$\mathbf{T}$表示优化过程中的神经纹理，$\text{clamp}$为钳位函数。
优化结束后，将神经纹理从(-1,1)线性映射到(0,1)，即可以BC7格式压缩存储。


\section{实验设计与分析}

基于DBC模型，使用Pytorch的C++版本实现了DXT格式的可微编解码器。
由于单模式的BC1至BC5格式较为简单，因此本章
的DBC模型仅使用多模式的可微BC6与可微BC7进行实验。
本章仅在神经压缩模型中进行实验，其余两个应用场景的实验在第四章进行。
实验过程中使用i7-13700KF和RTX 2080Ti进行测试。

\subsection{实验设置}

\paragraph{实验数据集}

在神经压缩模型的实验中，使用来自polyhaven.com\cite{PolyHaven}的 6 个公开的材质纹理集，
分别为Ukulele\_01、antique\_katana\_01、utility\_box\_02、chinese\_chandelier、
lubricant\_spray和Drill\_01。
每个纹理集包含 8 个通道，由 3 张纹理组成：3通道的漫反射纹理、2通道的法线纹理 和 3通道的ARM纹理（环境光遮蔽、粗糙度、金属度），
分辨率均为2048×2048(2K)。

\paragraph{标准DXT格式编解码器}

使用英伟达开发的纹理压缩工具NVTT3\cite{NVTT3}(NVIDIA Texture Tools 3)作为标准DXT格式编解码器。
NVTT3是一种通过CUDA加速的纹理压缩和图像处理的SDK，
可用于将纹理压缩为块压缩格式（包括 BC1-7 和 LDR ASTC），这些格式在磁盘和 GPU 内存中都保持较小的大小。
结合了DBC模型的神经压缩模型训练结束后，需要使用NVTT3对神经纹理以DXT格式进行压缩，
测试时使用从DXT格式解码的神经纹理，以验证DBC模型的有效性。

\paragraph{评估指标}

纹理压缩任务常用的评估指标是峰值信噪比(Peak Signal-to-Noise Ratio, PSNR)、
结构相似性\cite{wang2004image}(Structural Similarity, SSIM)，
以及FLIP\cite{andersson2020flip}。

PSNR是图像和视频处理领域一种常用的客观质量评价指标。
它用于衡量经过压缩或重建后的图像与原始图像之间的差异，PSNR 值越高，
说明失真越小，图像质量越好。
PSNR 的计算基于均方误差(Mean Squared Error, MSE)，其定义如下：
\begin{equation}
\text{MSE} = \frac{1}{MN} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} \left[ I(i,j) - K(i,j) \right]^2
\end{equation}
其中$M$ 和 $N$ 分别为图像的宽度和高度，$I(i,j)$ 和 $K(i,j)$ 分别表示原始图像和经过处理后的图像在像素 $(i,j)$ 处的像素值。
基于MSE，PSNR 的计算公式如下：
\begin{equation}
    \text{PSNR} = 10 \cdot \log_{10} \left( \frac{MAX^2}{\text{MSE}} \right)
\end{equation}
其中$MAX$ 表示像素的最大可能值。

虽然 PSNR 计算简单且易于理解，但它仅基于像素误差衡量图像质量，而未考虑人眼视觉系统的感知特性。例如，两幅图像的 PSNR 可能相同，但主观视觉效果可能存在明显差异。

SSIM\cite{wang2004image}是一种衡量图像质量的客观指标，旨在模拟人类视觉系统对图像质量的感知。
与PSNR不同，SSIM 不仅关注像素间的数值差异，还考虑了图像的结构信息，从而提供更符合人眼感知的质量评估。
SSIM 通过亮度(Luminance)、对比度(Contrast)和结构(Structure)三个分量计算图像相似度，其数学定义如下：
\begin{equation}
\text{SSIM}(x, y) = l(x, y)^\alpha \cdot c(x, y)^\beta \cdot s(x, y)^\gamma
\end{equation}
\begin{equation}
l(x, y) = \frac{2\mu_x\mu_y + C_1}{\mu_x^2 + \mu_y^2 + C_1}
\end{equation}
\begin{equation}
c(x, y) = \frac{2\sigma_x\sigma_y + C_2}{\sigma_x^2 + \sigma_y^2 + C_2}
\end{equation}
\begin{equation}
s(x, y) = \frac{\sigma_{xy} + C_3}{\sigma_x \sigma_y + C_3}
\end{equation}
其中$l(x, y)$ 为亮度比较函数，$c(x, y)$ 为对比度比较函数，
$s(x, y)$ 为结构相似性函数，
$\mu_x$ 和 $\mu_y$ 分别为图像 $x$ 和 $y$ 的均值，
$\sigma_x$ 和 $\sigma_y$ 分别为图像 $x$ 和 $y$ 的标准差，
$\sigma_{xy}$ 为图像 $x$ 和 $y$ 之间的协方差，$C_1$、$C_2$和$C_3$是稳定常数。

SSIM 的取值范围为 $[-1,1]$，SSIM的值越大则两幅图像的相似程度越高。
相比PSNR，SSIM 更符合人类视觉系统的感知特点，能够更准确地反映图像质量。
然而，SSIM 仍然存在一定局限性，例如对局部亮度变化较敏感。

FLIP\cite{andersson2020flip}是一种由 NVIDIA 提出的基于人类感知差异的图像质量评价指标，专用于计算机图形学中的渲染质量评估。
FLIP计算过程结合了人眼视觉特性和局部特征检测，以评估图像的感知质量差异。
首先，FLIP 采用对比敏感度函数(Contrast Sensitivity Function, CSF)对输入图像进行空间滤波，
以模拟人眼对不同空间频率的敏感性，并在感知均匀色彩空间中计算颜色误差，
以确保色彩差异符合人眼视觉特性。随后，FLIP 通过边缘检测和点状特征检测增强对小尺度结构（如锐利边缘、噪点等）的感知，
并采用局部对比度分析确保对高频细节的评估更符合视觉系统。
最终，FLIP 计算颜色误差 $\Delta E_c$ 和特征误差 $\Delta E_f$，并通过非线性组合：
\begin{equation}
    \Delta E = (\Delta E_c)^{1 - \Delta E_f}
\end{equation}
获得最终的感知误差值。该计算方式确保了特征误差对颜色误差的影响，
增强了对关键视觉区域（如边缘、纹理和亮度变化）的质量评估。
FLIP 的取值范围为 $[0,1]$，FLIP的值越小则图像的损失越小。

实验过程中对于PSNR与SSIM分别使用Python的图像处理库scikit-image\cite{scikit-image}
中的peak\_signal\_noise\_ratio与structural\_similarity方法进行计算。
对于FLIP使用Python的flip-evaluator库进行计算。

\paragraph{对比方法}

为了验证本章模型的有效性，选择了一些方法作为基准进行对比：

\begin{itemize}
\item BC6，BC7： 训练过程不使用DBC模型。
\item DBC6s，DBC7s：： 训练过程使用DBC模型，但使用固定的编码配置。
\end{itemize}

实验过程中为仅支持RGB通道的BC6与支持RGBA通道的BC7相关的实验分别使用3通道与4通道的特征网格，
相同高度和宽度下，
3通道/4通道神经纹理经过NVTT3导出的BC6/BC7格式大小相同，
因此可以直接进行比较。

\paragraph{实现细节}

神经压缩模型使用4个
大小分别为512x512、256x256、128x128、64x64的特征网格，对于DBC模型的可微BC7(DBC7)使用
4通道特征网格，对于DBC模型的可微BC6(DBC6)使用3通道特征网格。
神经网络使用两层全连接结构，隐藏层通道数为16，输入通道数为12，输出通道数为8（纹理集中一组纹理的通道数之和）。

神经压缩模型中使用的损失函数为原始纹理与重建纹理之间的均方误差，以及\ref{范围约束}中的
范围约束损失:
\begin{equation}
    L_{exp}=\| I(i,j) - \hat{I}(i,j) \|^2_F
\end{equation}
\begin{equation}
    L_{total}=L_{exp}+\lambda L_{clamp}
\end{equation}
其中$i$和$j$分别为纹理的像素坐标，$I$表示原始纹理，$\hat{I}$表示
神经压缩模型重建的纹理，$\lambda$表示范围约束损失的权重，DBC6实验时固定为0，DBC7实验时固定为0.1。

神经压缩模型中的神经纹理初始化为-1到1之间的均匀分布，神经网络权重和偏置项使用默认初始化。
将每个材质的纹理集中的一组纹理拼接成8通道的张量作为真实数据。学习率初始化为0.01，
使用Adam优化器先进行10000次迭代的预训练，预训练过程不对神经纹理使用任何压缩方法。
预训练完成后，重置Adam优化器并接入DBC6/DBC7模型继续训练。
DBC6/DBC7模型每次迭代过程中，对每4\times4块会穷举所有的编码配置进行编解码，并通过配置选择器选择编码误差最小的编解码结果作为
每4\times4块的输出。
训练过程使用学习率衰减策略，
若连续 40 次迭代训练损失不降，将学习率乘衰减系数 0.9。
每隔 50 次迭代使用NVTT3导出BC6/BC7格式的神经纹理进行测试，并计算真实损失，
保存真实损失最小的神经纹理与网络权重。
当连续 5 次（对应 250 次迭代）真实损失不降则停止训练。
第二次训练完成后使用NVTT3将神经纹理导出为BC6/BC7格式进行测试。

四个基准方法与上述的完整DBC6/DBC7模型分别进行实验。

\begin{itemize}
    \item BC6，BC7： 神经纹理预训练后直接使用NVTT3压缩为BC6/BC7格式进行测试。
    \item DBC6s，DBC7s： 神经纹理预训练后使用基于DBC模型的可微BC6/BC7继续训练，
    训练开始时对每4\times4块进行编码配置初始化，
    即对每4\times4块尝试所有的编码配置进行编解码，并通过配置选择器选择编码误差最小的编码配置。
    每次迭代过程中对每4\times4块使用初始化后固定的编码配置进行编解码，由于每个块的输出唯一，因此
    不需要使用配置选择器。第二次训练完成后使用NVTT3将神经纹理导出为BC6/BC7格式进行测试。
\end{itemize}

\subsection{实验结果与分析}

\subsubsection{对比实验}
\label{3:对比实验}
6个材质的纹理集上进行的实验结果如表\ref{3:6个材质的纹理集上进行的对比实验}所示，
对于每个材质，不使用DBC模型而是直接使用NVTT将神经纹理
导出为BC6与BC7格式的两种方法(BC6/BC7)都取得了最差的结果。
两个使用固定配置的DBC模型(DBC6s/DBC7s)相比BC6/BC7取得了更好的结果,
证明向神经压缩模型加入DBC模型并进行联合优化有效降低了神经纹理经过DXT格式压缩造成的纹理集的重建损失。

\begin{table*}[htbp]
    \centering
    \caption{6个材质的纹理集上进行的对比实验结果}
    \label{3:6个材质的纹理集上进行的对比实验}        
    \resizebox{\linewidth}{!}{
    % \begin{tabular}{ccccccccccccccccccc}
    %     \toprule
    %     & \multicolumn{3}{c}{Ukulele\_01} & \multicolumn{3}{c}{antique\_katana\_01} & \multicolumn{3}{c}{utility\_box\_02} & \multicolumn{3}{c}{chinese\_chandelier} & \multicolumn{3}{c}{lubricant\_spray} & \multicolumn{3}{c}{Drill\_01}\\
    %               & PSNR(↑)  & SSIM(↑) & FLIP(↓)& PSNR(↑) & SSIM(↑) & FLIP(↓)& PSNR(↑) & SSIM(↑) & FLIP(↓) & PSNR(↑) & SSIM(↑)& FLIP(↓) & PSNR(↑)& SSIM(↑)& FLIP(↓)& PSNR(↑) & SSIM(↑)& FLIP(↓)\\
    %               \midrule
    %               BC6       & 22.3005  & 0.6716  & 0.2713 & 24.1197 & 0.7007  & 0.2161 & 23.8151 & 0.6977  & 0.2341  & 20.1739 & 0.604  & 0.3457 & 22.6572 & 0.6651 & 0.2726 & 22.6281 & 0.7039 & 0.2976  \\
    %               DBC6s     & \textbf{27.1085}  & \textbf{0.7625}  & \textbf{0.1705} & 27.8752 & 0.8197  & 0.1332 & 28.027  & 0.7853  & 0.1472  & 25.7551 & 0.7407 & 0.2197 & 26.0462 & 0.7785 & 0.1846 & 26.8157 & 0.8328 & 0.163  \\
    %               DBC6      & 27.083   & 0.7622  & 0.1707 & \textbf{27.9227} & \textbf{0.8233}  & \textbf{0.1322} & \textbf{28.0362} & \textbf{0.7877}  & \textbf{0.1453}  & \textbf{25.8831} & \textbf{0.7453} & \textbf{0.2163} & \textbf{26.0767} & \textbf{0.775}  & \textbf{0.1848} & \textbf{26.8316} & \textbf{0.8295}  & \textbf{0.1693}   \\
    %               \midrule
    %               BC7       & 23.0234  & 0.6685  & 0.2606 & 25.0525 & 0.6602  & 0.2262 & 25.0392 & 0.7163  & 0.2338  & 22.45   & 0.6358 & 0.3009 & 21.4505 & 0.6852 & 0.2457 & 22.2064 & 0.7357 & 0.2971   \\
    %               DBC7s     & 30.2512  & 0.8221  & 0.1087 & 30.602  & 0.8683  & 0.0919 & 30.8006 & 0.8338  & 0.1068  & 29.6132 & 0.8223 & 0.1378 & 29.5706 & 0.8618 & 0.0949 & 31.8172 & 0.9084 & 0.0986  \\
    %               DBC7      & \textbf{30.534}   & \textbf{0.8277}  & \textbf{0.1018} & \textbf{30.8209} & \textbf{0.8736}  & \textbf{0.0871} & \textbf{31.154}  & \textbf{0.8412}  & \textbf{0.0998}  & \textbf{29.9245} & \textbf{0.8303} & \textbf{0.1304} & \textbf{29.7846} & \textbf{0.8666} & \textbf{0.0905} & \textbf{32.2309} & \textbf{0.9156} & \textbf{0.0893}   \\
    %     \bottomrule
    % \end{tabular} 
\begin{tabular}{cccccccc}
        \toprule
        材质名称                         &    评价指标     & BC6 & DBC6s & DBC6 & BC7 & DBC7s & DBC7 \\
        \midrule
        \multirow{3}{*}{Ukulele\_01}         & PSNR(↑) & 22.3005 & \textbf{27.1085} & 27.083 & 23.0234 & 30.2512 & \textbf{30.534} \\
                                             & SSIM(↑) & 0.6716 & \textbf{0.7625} & 0.7622 & 0.6685 & 0.8221 & \textbf{0.8277} \\
                                             & FLIP(↓) & 0.2713 & \textbf{0.1705} & 0.1707 & 0.2606 & 0.1087 & \textbf{0.1018} \\
        \midrule
        \multirow{3}{*}{antique\_katana\_01} & PSNR(↑) & 24.1197 & 27.8752 & \textbf{27.9227} & 25.0525 & 30.602 & \textbf{30.8209} \\
                                             & SSIM(↑) & 0.7007 & 0.8197 & \textbf{0.8233} & 0.6602 & 0.8683 & \textbf{0.8736} \\
                                             & FLIP(↓) & 0.2161 & 0.1332 & \textbf{0.1322} & 0.2262 & 0.0919 & \textbf{0.0871} \\
        \midrule
        \multirow{3}{*}{utility\_box\_02}    & PSNR(↑) & 23.8151 & 28.027 & \textbf{28.0362} & 25.0392 & 30.8006 & \textbf{31.154} \\
                                             & SSIM(↑) & 0.6977 & 0.7853 & \textbf{0.7877} & 0.7163 & 0.8338 & \textbf{0.8412} \\
                                             & FLIP(↓) & 0.2341 & 0.1472 & \textbf{0.1453} & 0.2338 & 0.1068 & \textbf{0.0998} \\
        \midrule
        \multirow{3}{*}{chinese\_chandelier}    & PSNR(↑) & 20.1739 & 25.7551 & \textbf{25.8831} & 22.45 & 29.6132 & \textbf{29.9245} \\
                                                & SSIM(↑) & 0.604 & 0.7407 & \textbf{0.7453} & 0.6358 & 0.8223 & \textbf{0.8303} \\
                                                & FLIP(↓) & 0.3457 & 0.2197 & \textbf{0.2163} & 0.3009 & 0.1378 & \textbf{0.1304} \\
        \midrule
        \multirow{3}{*}{lubricant\_spray}    & PSNR(↑) & 22.6572 & 26.0462 & \textbf{26.0767} & 21.4505 & 29.5706 & \textbf{29.7846} \\
                                             & SSIM(↑) & 0.6651 & 0.7785 & \textbf{0.775} &0.6852 & 0.8618 & \textbf{0.8666} \\
                                             & FLIP(↓) & 0.2726 & 0.1846 & \textbf{0.1848} & 0.2457 & 0.0949 & \textbf{0.0905} \\
        \midrule
        \multirow{3}{*}{Drill\_01}           & PSNR(↑) & 22.6281 & 26.8157 & \textbf{26.8316} & 22.2064 & 31.8172 & \textbf{32.2309} \\
                                             & SSIM(↑) & 0.7039 & 0.8328 & \textbf{0.8295} & 0.7357 & 0.9084 & \textbf{0.9156} \\
                                             & FLIP(↓) & 0.2976 & 0.163 & \textbf{0.1693} & 0.2971 & 0.0986 & \textbf{0.0893} \\
        \bottomrule
    \end{tabular}    
}   
\end{table*}

大部分实验中，每次迭代穷举所有编码配置的DBC模型(DBC6/DBC7)相比固定配置的DBC6s/DBC7s取得了更好的结果。
证明DBC模型支持编码配置动态选择的编解码器框架与固定编码配置的仅解码框架相比具有更好的编码质量，
同时更加接近标准的DXT编解码器，因此对神经纹理的优化效果更好。
其中DBC7在6组实验中都比DBC7s结果更好，
但DBC6在Ukulele\_01的实验中结果稍差于DBC6s，
其余5组实验中相比DBC6s的提升幅度与DBC7相比也更少。
原因是由于BC6的颜色端点量化过程较难进行可微模拟，
因此DBC模型仅对BC6的权重进行量化，导致与标准BC6编解码过程具有一定差异，
这个差异使得编码误差的计算准确性不如对颜色端点与权重都进行了量化的
BC7，最终导致了编码配置的选择效果弱于BC7，因此DBC6相比DBC6s的提升幅度
小于DBC7相比DBC7s的提升幅度。

BC7的相关方法(BC7/DBC7s/DBC7)相较于BC6的相关方法(BC6/DBC6s/DBC6)取得更好的结果，
主要原因有两个，首先相同存储空间BC7相比BC6可以多存储一个通道的数据，
其次DBC模型对BC7的颜色量化与权重都进行了模拟量化，而对于BC6由于颜色量化过程较难模拟，
仅对权重进行了模拟量化，因此与标准的BC6编解码器会有一定差异，导致对神经纹理的优化效果弱于BC7。
% LDR格式BC7的相关方法(BC7/DBC7s/DBC7)与HDR格式BC6的相关方法(BC6/DBC6s/DBC6)的对比结果
% 也证明通过范围约束损失使得浮点形式的神经纹理可以使用LDR格式压缩的有效性。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{figures/nm_v3.pdf}
    \caption{4个材质的纹理集上重建纹理的可视化结果}
    \label{fig:nm_v3}
\end{figure}

对其中4组实验的重建纹理进行了局部放大的可视化便于进行细节的比较，
结果如图\ref{fig:nm_v3}所示。其中从上至下分别是
lubricant\_spray、Ukulele\_01、
antique\_katana\_01和utility\_box\_02的三张重建纹理（漫反射纹理、法线纹理、ARM 纹理），
从左至右每一列是不同的对比方法，最右侧是无损的参考纹理。
横向对比每一列可以看出，
对于预训练的神经纹理直接使用BC6/BC7压缩会产生比较严重的伪影。
使用DBC模型的方法(DBC6s/DBC6/DBC7s/DBC7)很大程度上减轻了
重建纹理中的伪影，视觉效果上比较接近参考纹理。
其中DBC7s/DBC7相比DBC6s/DBC6的结果具有更好的视觉效果，
与表\ref{3:6个材质的纹理集上进行的对比实验}中的实验结果相符。

DBC7与DBC6相比DBC7s与DBC6s在视觉效果上的提升不太明显，
但在一些纹理细节上表现出了提升。例如第一行中lubricant\_spray
的漫反射纹理中条形码部分DBC7相比DBC7s更加清晰，
第九行antique\_katana\_01的ARM 纹理中字体部分
更平滑。


\subsubsection{性能测试}
\label{3:性能测试}
在6个材质的纹理集上进行不同方法的性能测试，
实验结果取6次实验的平均值。
实验结果如表\ref{3:6个材质的纹理集上进行的性能实验}所示，
其中DBC6s与DBC7s每次迭代的运行时间相比DBC6与DBC7短很多。
这是因为目前的编码配置选择器通过穷举的方法选择配置，
而DBC6在每次迭代过程进行可微编解码时，需要计算32种双分区+1种单分区
共33种编码配置，DBC7需要计算64种双分区+1种单分区
+4种旋转\times3种不同量化方案共77种编码配置，
因此DBC7与DBC6的计算量相比DBC7s与DBC6s显著增加，
DBC7由于编码配置种类更多，因此计算量的增加更加明显。
下一章将对配置选择器进行改进避免穷举所有配置
导致的速度缓慢问题。

从结果可以看出DBC7s相比DBC6s需要更多的迭代次数，
原因主要有两个，
首先为了保证使用NVTT3导出的BC6/BC7格式神经纹理具有相同
的大小，DBC7实验使用4通道的神经纹理，
DBC6实验使用3通道的神经纹理，因此DBC7需要更多的迭代次数才能
收敛。其次由于实验中的停止策略基于真实误差，
而真实误差的计算过程会使用NVTT3导出神经纹理，
BC7的模拟量化过程更完整，因此可以进行更多迭代
而不会出现较早出现类似过拟合的现象。
BC6的量化过程不完整导致更容易出现过拟合。

\begin{table*}[htbp]
    \centering
    \caption{6个材质的纹理集上进行的性能测试结果}
    \label{3:6个材质的纹理集上进行的性能实验}        
    %\resizebox{\linewidth}{!}{
    \begin{tabular}{lcccccccccccccccccc}
        \toprule
                                    & BC6 & DBC6s & DBC6 & BC7  & DBC7s & DBC7 \\
        \midrule
        每次迭代的平均运行时间(ms)  & 33  &  80    & 1012 & 35   & 171   &  2938 \\
        优化完成的平均迭代次数      & -   &  2200  & 2083 & -   & 3750   &  4416 \\
        优化完成的平均时间(min)     & -   &  3     & 35   & -   & 11      &  216\\
        \bottomrule
\end{tabular} %}   
\end{table*}

\subsubsection{消融实验}

为了验证DBC模型各个模块的有效性，对模型中的各个模块在
6个材质的纹理集上进行了消融实验。
由于\ref{3:对比实验}已经证明了支持编码配置动态选择
的DBC6/DBC7相比固定配置的DBC6s与DBC7s的优势，
因此消融实验在速度更快的固定编码配置的DBC6s与DBC7s上进行。
\ref{模拟量化}为DBC模型加入了模拟量化，并使用直通估计器
STE\cite{bengio2013estimating}近似舍入函数的梯度。
\ref{范围约束}为DBC模型加入了范围约束损失，将神经纹理
的范围约束在BC7格式支持的LDR范围内。
因此本节构建了如下DBC模型的变体：
\begin{itemize}
    \item DBC7s w/o $L_{clamp}$：移除了范围约束损失。
    \item DBC7s w/o STE：移除了模拟量化。
    \item DBC6s w/o STE：移除了模拟量化。
\end{itemize}
模型其余参数保持不变，具体实验结果如表\ref{3:6个材质的纹理集上进行的消融实验}所示。

从消融实验结果中可以观察到在6个材质的纹理数据集上，
无论是删除范围约束损失，
还是模拟量化，
DBC6s/DBC7s的性能都明显下降，这验证了本章提出的DBC模型中
模拟量化和范围约束损失的必要性。

\begin{table*}[t]
    \centering
    \caption{6个材质的纹理集上进行的消融实验结果}
    \label{3:6个材质的纹理集上进行的消融实验}        
    \resizebox{\linewidth}{!}{
    % \begin{tabular}{ccccccccccccccccccc}
    %     \toprule
    %     & \multicolumn{3}{c}{Ukulele\_01} & \multicolumn{3}{c}{antique\_katana\_01} & \multicolumn{3}{c}{utility\_box\_02} & \multicolumn{3}{c}{chinese\_chandelier} & \multicolumn{3}{c}{lubricant\_spray} & \multicolumn{3}{c}{Drill\_01}\\
    %                            & PSNR(↑)  & SSIM(↑) & FLIP(↓)& PSNR(↑) & SSIM(↑) & FLIP(↓) & PSNR(↑) & SSIM(↑) & FLIP(↓) & PSNR(↑) & SSIM(↑)& FLIP(↓)& PSNR(↑) & SSIM(↑)& FLIP(↓)& PSNR(↑) & SSIM(↑)& FLIP(↓)\\
    %     \midrule
    %     DBC7s w/o $L_{clamp}$  & 28.6012  & 0.7932  & 0.1393 & 29.1323 & 0.8000 & 0.1295 & 29.4279 & 0.8041 & 0.1355 & 27.5207 & 0.7758 & 0.1748 & 28.4018 & 0.8405 & 0.1153 & 28.9067 & 0.8469 & 0.1489  \\
    %     DBC7s w/o STE          & 28.8298  & 0.7949  & 0.1373 & 29.4041 & 0.8098 & 0.1230 & 29.6283 & 0.8100 & 0.1310 & 27.7152 & 0.7818 & 0.1702 & 26.8598 & 0.8098 & 0.1396 & 29.2267 & 0.8580 & 0.1438  \\
    %     DBC7s                  & \textbf{30.2512}  & \textbf{0.8221}  & \textbf{0.1087} & \textbf{30.602}  & \textbf{0.8683}  & \textbf{0.0919} & \textbf{30.8006} & \textbf{0.8338}  & \textbf{0.1068}  & \textbf{29.6132} & \textbf{0.8223} & \textbf{0.1378} & \textbf{29.5706} & \textbf{0.8618} & \textbf{0.0949} & \textbf{31.8172} & \textbf{0.9084} & \textbf{0.0986}  \\        
    %     \midrule
    %     DBC6s w/o STE          & 25.1120  & 0.7283  & 0.2027 & 25.8527 & 0.7740 & 0.1647 & 25.6907 & 0.7515 & 0.1815 & 23.2535 & 0.6880 & 0.2678 & 24.1332 & 0.7084 & 0.2318 & 24.4736 & 0.7804 & 0.2131 \\
    %     DBC6s                  & \textbf{27.1085}  & \textbf{0.7625}  & \textbf{0.1705} & \textbf{27.8752} & \textbf{0.8197}  & \textbf{0.1332} & \textbf{28.027}  & \textbf{0.7853}  & \textbf{0.1472}  & \textbf{25.7551} & \textbf{0.7407} & \textbf{0.2197} & \textbf{26.0462} & \textbf{0.7785} & \textbf{0.1846} & \textbf{26.8157} & \textbf{0.8328} & \textbf{0.163}  \\
    %     \bottomrule
    % \end{tabular} 
    \begin{tabular}{ccccccc}
        \toprule
        材质名称 & 评价指标 & \makecell{DBC7s \\ w/o $L_{clamp}$} & \makecell{DBC7s \\ w/o STE} & DBC7s & \makecell{DBC6s \\w/o STE} & DBC6s \\
        \midrule
        \multirow{3}{*}{Ukulele\_01}         & PSNR(↑) & 28.6012 & 28.8298 & \textbf{30.2512} & 25.1120 & \textbf{27.1085} \\
                                             & SSIM(↑) & 0.7932 & 0.7949 & \textbf{0.8221} & 0.7283 & \textbf{0.7625} \\
                                             & FLIP(↓) & 0.1393 & 0.1373 & \textbf{0.1087} & 0.2027 & \textbf{0.1705} \\
        \midrule
        \multirow{3}{*}{antique\_katana\_01} & PSNR(↑) & 29.1323 & 29.4041 & \textbf{30.602} & 25.8527 & \textbf{27.8752} \\
                                             & SSIM(↑) & 0.8000 & 0.8098 & \textbf{0.8683} & 0.7740 & \textbf{0.8197} \\
                                             & FLIP(↓) & 0.1295 & 0.1230 & \textbf{0.0919} & 0.1647 & \textbf{0.1332} \\
        \midrule
        \multirow{3}{*}{utility\_box\_02}    & PSNR(↑) & 29.4279 & 29.6283 & \textbf{30.8006} & 25.6907 & \textbf{28.027} \\
                                             & SSIM(↑) & 0.8041 & 0.8100 & \textbf{0.8338} & 0.7515 & \textbf{0.7853} \\
                                             & FLIP(↓) & 0.1355 & 0.1310 & \textbf{0.1068} & 0.1815 & \textbf{0.1472} \\
        \midrule
        \multirow{3}{*}{chinese\_chandelier} & PSNR(↑) & 27.5207 & 27.7152 & \textbf{29.6132} & 23.2535 & \textbf{25.7551} \\
                                             & SSIM(↑) & 0.7758 & 0.7818 & \textbf{0.8223} & 0.6880 & \textbf{0.7407} \\
                                             & FLIP(↓) & 0.1748 & 0.1702 & \textbf{0.1378} & 0.2678 & \textbf{0.2197} \\
        \midrule
        \multirow{3}{*}{lubricant\_spray}    & PSNR(↑) & 28.4018 & 26.8598 & \textbf{29.5706} & 24.1332 & \textbf{26.0462} \\
                                             & SSIM(↑) & 0.8405 & 0.8098 & \textbf{0.8618} & 0.7084 & \textbf{0.7785} \\
                                             & FLIP(↓) & 0.1153 & 0.1396 & \textbf{0.0949} & 0.2318 & \textbf{0.1846} \\
        \midrule
        \multirow{3}{*}{Drill\_01}           & PSNR(↑) & 28.9067 & 29.2267 & \textbf{31.8172} & 24.4736 & \textbf{26.8157} \\
                                             & SSIM(↑) & 0.8469 & 0.8580 & \textbf{0.9084} & 0.7804 & \textbf{0.8328} \\
                                             & FLIP(↓) & 0.1489 & 0.1438 & \textbf{0.0986} & 0.2131 & \textbf{0.163} \\
        \bottomrule
    \end{tabular}
}   
\end{table*}

\section{本章小结}

本章提出了DXT格式的可微块压缩模型DBC。
引言部分阐述了将纹理块压缩方法
直接应用到神经纹理上面临的较高质量损失问题。
然后分析了DXT格式的主要特点与编码过程的本质问题。
接下来提出了模型的整体框架，
包括可微编码器、可微解码器和配置选择器三部分。
之后阐述了可微编解码器的具体实现方法，给出了编码过程与解码过程的数学表达。
然后介绍了模拟量化的实现方法、
编码配置选择器的设计以及范围约束损失。
最后在神经压缩模型中对本章所提出的方法进行测试，
以证明所提出的方法的有效性。



